```
セキュリティ・キャンプ全国大会2025
専門コースB【プロダクトセキュリティクラス】応募課題

必答問題（Q.1 から Q.3 まで）の問題すべてと、選択問題（Q.4 から Q.6 まで）の中の少なくとも 1 問に解答してください。

----------------------
【補足事項】
----------------------

(1) この応募課題の設問は、どれも応募してくださるあなたの「現状の知識・経験の広さ・深さ」「興味・感心の範囲や強さ」を汲み取るためのものです。ぜひ自分の興味関心や知識、考えたこと、疑問等を各設問への解答として表現していただければと思います。
(2) 各設問で求めている内容が適切に盛り込まれている限り、解答の文字数の大小や日本語表現の巧拙は評価に大きな影響を与えません。また、日本語表現に関する軽微な誤りは評価に全く影響しません。とりわけ誤字脱字はあまり気にしなくて大丈夫です。
(3) 誇張を感じられる解答よりも、 ご自分の応募時点での経験や理解が真摯に表現できている解答を歓迎します。とりわけ、分からないことや確信の持てないことがあるときには「ここまでは分かったが、ここからは分からない」「これらの事例から ?でないかと推測できるが、?であると断言できるかは不明である」というような記述を含めていただけると嬉しいです。
(4) 選択問題においては「適切な論拠をもとにした、各設問に対して必要十分な情報を、適切な論理構造で表現できているか」を意識してください。
(5) 選択問題はきっかり 1 問のみ解答していただいても大丈夫です。2 問以上ご解答いただけると、選考においては、より応募してくださるあなたの魅力を汲み取りやすくなるかもしれません。なお、選びにくい問題・難易度が高そうな問題に挑戦している応募者の評価も高めになる傾向がありました。
(6) 解答に関して何かしらの実験を行う際には、法令等を必ず遵守してください。
(7) 最近著しい進化を遂げる LLM サービスを利用して解答を作成しても構いません。限られた期間で最大限によいと思える解答を作ること、それを通して自分の見識を広げるのに、それらの技術が貢献してくれるかもしれません。

--------------------
【必答問題】
----------------------

■ Q.1（応募のモチベーションについて）
「プロダクトセキュリティクラス」の講義のうち、特に受講したいと思う講義（複数可）に関して、その講義で「どのようなことを・なぜ学びたいか」を教えてください。とりわけ「なぜ学びたいか」の部分に関連して、いま応募を考えているあなたが感じておられる課題意識や、あなたの関心領域が伝わってくるような解答を歓迎します。

■ Q.2（これまでの経験について）
以下の経験について、差し支えのない範囲でできるだけ具体的に教えてください:
(1) Web アプリケーションの設計・開発経験（※ どんな些細なものでも構いません）
(2) パブリッククラウド技術の利用・構築経験（※ どんな些細なものでも構いません）
(3) 一般のプログラミングの経験やチームでの開発経験（※ 使ったことのある言語や、その用途などを教えてください。レイヤは問いません）
(4) コンテナ技術の利用経験
(5) CI/CD 環境のセットアップ・利用経験
なお、この問は「この応募課題を提出する時点での経験」を問うものです。この応募課題を見た時点での経験はなくても構いませんし、この応募課題の記入にあわせての学習を歓迎します。

■ Q.3（あなたの感心・興味について）Web に関連するサービス・プロダクトを作って提供することに関連する技術で、いまあなたが興味を持っているものがあれば、それについて自由に説明してください。少しでも Web との関連性がある技術であれば、それがハードウェア領域に近いものでも、ソフトウェア領域に近いものでも構いません。

----------------------
【選択問題】
----------------------

■ Q.4（Web に関連する脆弱性・攻撃技術の検証）
「Top 10 web hacking techniques of 2024」( https://portswigger.net/research/top-10-web-hacking-techniques-of-2024 ) は、Web に関するセキュリティリサーチャーの投票により作成された、2024 年に報告された興味深い Web に関する攻撃テクニック 10 選です。この Top 10 中の事例の中で、興味を持てたもの 1 つに関して、以下を説明してください。
(1) 事例の概要
(2) 攻撃手法の詳細
(3) その他その事例に関して感じたこと・気がついたこと
なお、本設問では、関連する仕様や攻撃の適用可能な条件についての詳細な理解が垣間見えるような記述や、理解を深めるために行ったこと（例: ローカルで行った再現実験等）に関する記述を歓迎します。

■ Q.5（パスキーに関連する標準や実装の調査）
(1) 任意のパスキーが使用されているサービスを実際に利用して使用感を調査したうえで、技術的・運用的・UXの観点から、あなたが課題だと思う点を述べてください。また、その解決策についても考えてください。なお、実際に利用できる環境にない場合はドキュメントの調査のみとして、使用感が分かる範囲で想像できる課題を考察してください。
(2) 認可と認証の違いについて、例を挙げて説明したうえで、OAuth 2.0 や OpenID Connect（OIDC）とパスキーの仕様（WebAuthn）の関係について説明してください。
(3) 従来の認証方式（パスワード、OTP、SMS認証など）と比較した場合、パスキーのメリットとデメリットを述べてください。
(4) 従来の認証方式（パスワード、OTP、SMS認証など）で提供されたWebアプリケーションにパスキーを実装するとき、サーバー側でどのような変更が必要ですか？
(5) あなたが企業のエンジニアだった場合、経営陣にパスキーの導入を提案するとしたら、どのようなポイントを説明しますか？

■ Q.6（APIに関するセキュリティへの考慮）
(1) あなたが考える「APIに対する最大のセキュリティ脅威」を1つ挙げ、それに対する攻撃者の視点での調査プロセス（情報収集・攻撃手法の検討など）を考察し、それを防ぐための具体的な対策を述べてください。（ヒント：攻撃者の調査方法には、OSINT、リクエスト改ざん、脆弱性スキャン、レスポンス分析などが含まれます）
(2) マイクロサービスアーキテクチャでは、サービス間通信を安全に行うためのセキュリティ対策が必要です。マイクロサービス間のAPI通信におけるセキュリティ課題を1つ挙げ、それを解決するための手法を説明してください。
(3) APIゲートウェイは、マイクロサービスのエントリーポイントとして機能します。APIゲートウェイを導入することで防げるセキュリティリスクを1つ挙げ、それをどのように設定・運用すべきか説明してください。
(4) あなたのプロダクトのAPIが不正アクセスを受けている可能性があると判断された場合、どのようなログを確認し、どのような対応プロセスを取るべきか説明してください。
```

# Q.1「プロダクトセキュリティクラス」の講義のうち、特に受講したいと思う講義（複数可）に関して、その講義で「どのようなことを・なぜ学びたいか」を教えてください。とりわけ「なぜ学びたいか」の部分に関連して、いま応募を考えているあなたが感じておられる課題意識や、あなたの関心領域が伝わってくるような解答を歓迎します。

私は第1希望としてB3『デジタルアイデンティティの基礎と最新認証技術パスキーの実装』
を希望し、第2希望としてB2『設計・開発・テストにおけるセキュリティの実践と考え方を知ろう』B5『モダンなプロダクト開発を攻撃者の視点で捉える』を希望します。
私はこのセキュリティキャンプに参加するにあたって「単に動くだけのプロダクトを作る開発者」から「安全に使えるプロダクトを設計・提供・説明ができる開発者」になりたいと強く考えています。

最初にB3の講義を受けたい理由について説明します。大きく分けて３つあります。

第一にサービスを提供する者が認証に関わる正確な知識を持たないことは提供者として致命的であり無責任だと考えているからです。認証のシステムが扱うのは利用者の個人情報であり、もしそれらが流出などすれば多額の損害賠償や補償、復旧や機会損失など多くの損害が出ます。さらにもしそれが要配慮個人情報だった場合には取り返しのつかない問題にもなり得ます。

また私は認証周りに関して苦い経験があります。Q.2にもありますが私は知人とオンラインゲームを作成しWebサイト上で公開しています。そのプロジェクトの中で私が担当した部分の一つがランキング機能です。締め切りが近づきシステムが動作することを最優先にせざるを得ず、「認証・認可・制限」の設計を怠ったまま運用していました。幸いにもクリティカルな情報や不正にデータの操作が行われませんでしたが、不審なGETやPOSTが多くありました。私はこのような脆弱なシステムを構築してしまったことについて深く反省しています。

IPAの応用情報やAWS SAAを取得する中で認証の重要性を学んだのでこのように考えています。

第二に私は既存のマネージドサービスに大きく依存していることに気が付き、本質を知りたいとワクワクしているからです。これまでモバイルアプリやゲーム開発を起点としてプロダクトを作成する際は、Firebase やAWS Cognitoといった既製品を活用しました。これらのサービスは非常に優れており、内部構造について深く知らなくても利用することができます。しかしながら技術の背景や他の方式との比較を行う際には、自分の理解が不足していることを痛感しました。私は技術者として経営者などの関係者に対して説明できるエンジニアにステップアップしたいと考えています。

第三に公開鍵暗号についての強い関心を持っているからです。私は過去にGPGを使って、遊び半分ながらも署名や暗号化の仕組みを試した経験があります。暗号化したテキストファイルを知人と送り合い秘密のメッセージ会話をしました。その中で改めて感心したのは、公開鍵と秘密鍵の信頼関係という抽象的な概念を、論理的に具体的な手法で実装している点でした。公開鍵暗号はありとあらゆる場所で使われていますが、セキュリティの最前線での使われ方に興味があります。

この講座を希望するにあたって応用情報の教科書を読み返したり、「パスキーのすべて─⁠─導入・UX設計・実装」「OAuth、OAuth認証、OpenID Connectの違いを整理して理解できる本[2024改訂]」という本を新しく購入し勉強したりしました。そして勉強を通して自分は認証について全然知らないということを強く自覚しました。自分の無知を認識したことが、デジタルアイデンティティとパスキーについて深く学びたいという強い動機につながっています。

次に、第2希望としてB2『設計・開発・テストにおけるセキュリティの実践と考え方を知ろう』およびB5『モダンなプロダクト開発を攻撃者の視点で捉える』の講義を希望する理由について説明します。

私は過去にUnityを用いたオンラインゲームの開発を行いましたが、その際スケジュールに追われ、脆弱性への対応やセキュアな設計が後回しになってしまいました。その結果、「ボールが無限に増殖する」といったバグが発生してしまいました。しかも増殖するボールはゲームのルールに大きく影響を与えるアイテムでした。実際は数秒経てば元に戻るようになっていたものの、サービスの根本まで侵食するバグになってしまいました。その時はフリーゲームのため許容できる問題でしたが、もしこれが課金アイテムやゲーム内通貨だったとすれば、サービス運営やユーザーと訴訟になっていたかもしれません。

この経験を通じて、単に機能を実装するだけでなく、プロダクトのセキュリティや堅牢性を設計段階から考慮することが極めて重要であることを痛感しました。B2の講義では、設計・開発・テストというプロダクトライフサイクルの各段階におけるセキュリティの考え方や実践方法を具体的に学びたいと考えています。自分が関わるプロダクトを「ただ動く」ものから「安全で信頼できる」ものへと進化させるために、この知識が必須だと感じています。

また、B5の講義では、プロダクト開発を「攻撃者の視点」で捉えることに興味があります。開発者としての視点だけでなく、攻撃者がどのようにプロダクトの脆弱性を見つけ、悪用するのかを理解することによって、未然に攻撃を防ぐ設計や実装ができるようになると考えています。セキュリティをプロダクト設計の中核に据える意識を養うためにも、この視点が重要であると強く認識しています。

以上の理由から、B2とB5の講義を通じて、セキュアなプロダクト開発の実践的スキルと攻撃者視点でのリスク評価能力を高めたいと考えています。

私は活躍できるエンジニアになるために体系的に学び、一朝一夕では身につかない幹の部分の知識を強くしていきたいです。そしてそのためにはセキュリティキャンプという環境が非常に適していると考えています。
業界の最前線を切り拓いている講師の方から基礎と現在の技術について、自分一人では到達することのできない深い知識を得られると確信しているからです。

「誰かが担っていた責任を自分が担えるようになる」ための第一歩としたいです。

---

# ■ Q.2（これまでの経験について）

## (1) Webアプリケーションの設計・開発経験

私はWeb開発の経験は他の応募者に比べて少ない面もあると思っています。しかし私にはFlutterというフレームワークを用いて最後まで完成させ公開した経験があります。

ウェブアプリ URL 【シカプリ】[https://qualification-app.web.app/](https://qualification-app.web.app/)

このアプリを制作した背景には、私自身の体験があります。私は基本情報技術者試験・応用情報技術者試験を独学で取得しましたが、地域に信頼できる相談相手がおらず、情報の多くはインターネット頼みでした。しかしネット上の情報は広告目的のものも多く、情報の質は**玉石混淆**でした。そこで勉強した人の知見を集め、これから学ぶ人を応援する場所を作りたいと考え、このアプリを開発しました。

このアプリではいくつか機能を実装しているので紹介します。

- メールアドレスの認証とGoogleアカウントでのログインからアカウント削除機能
- 質問やおすすめの参考書を共有できる機能
- 参考書のランキング機能
- LINEのような質問機能

バックエンドにはFirebaseを採用し、主に「Firestore Database」（**キーバリュー型データベース**）と「Authentication」のサービスを活用しています。これらを通じて、リアルタイムなデータの反映やユーザー管理といった機能を実現しました。

失敗や課題についてはFirebaseという高度に抽象化されたサービスを使ったため、内部でどのような通信や処理が行われているのか十分に理解できていないということです。

また「認可」について問題があると考えています。データベースへのアクセス制限のルールは存在していますが、「ログインしていないと見られない」「自分以外のデータについては削除はできないが無制限に書き込み、読み込みができる」という２つのルールのみです。そのため任意の長さのデータが無制限に書き込めるという脆弱性が存在します。例えば、オススメの参考書の名前を入力する機能では、フロントエンド側でバリゲーションのチェックをしていなかったので何文字までも入力することができます。解決策としてはフロントエンドのチェックだけでは入力欄のチェックのし忘れや直接パケットを送られるということに対して対策できないのでバックエンド側でも長さを調べる仕組みを導入するべきだと思います。

また他の人が作成したデータの部分にもデータの書き込み権限があるという問題もあります。データベースのテーブルごとに権限を設定していている状況で、一つのテーブルに多くの情報が詰め込まれているので、本来は他の人が操作するべきではないフィールドにも赤の他人に権限があります。例えば他のユーザーのToDoリストやお気に入りの資格の情報が同じテーブルにあるので全てが読み込み可能になっていました。もちろん、フロントエンド側ではできないようにていますが致命的な脆弱性です。解決策としては権限の管理の粒度を小さくすることが効果的だと思います。正規化をしてテーブルを適切に分けて、レコードのユーザーIDが一致しているときのみ権限を与える設計がより安全だと考えます。

これを解決するには様々なデータを一つのデータベースに格納するのではなく複数のテーブルに分け、それぞれにルールを設定していく必要があると考えています。データベース設計を一からやり直すことでデータの不整合と冗長性も解消することもできます。

反省点はいくつかありましたが、一方で良い点についても２つ紹介します。

１つ目は、私がバックエンドの世界に踏み込むきっかけとなったことです。以前はUnityを主に活用してオフラインゲームを作成していました。それまではローカルで完結することしか行えなかったのがデータベースや認証を活用することで、実装の自由度が何十倍にもなり強い衝撃を受けたことを今でも覚えています。それからもっと知識を深めるべくAWSを勉強しAWS SAAの取得につながりました。知らない分野のことを知り、第一歩を踏み出すのに時間はかかりましたが調べられるようになりレベルアップをしたと思います。

２つ目はプロダクトの構想・設計について考え改めるきっかけになりました。

この作品は「U-22プログラミング・コンテスト」に提出するために作りました。高い評価を得るために機能を詰め込み、作品をラグジュアリーに見せることに必死でした。しかしながら以前までいけてた第一選考落ちという結果に終わってしまいました。この経験から、プロダクトは闇雲に機能を増やすのではなく、本当にユーザーが求める核となる機能に集中することが重要だと考えるようになりました。そもそも想定ユーザーの要件すら満たしていないプロダクトは使われません。一度の失敗から本当に重要な視座を得られたと感じています。

この企画にエントリーするにあたり、Webについてもっと知ろうと思いReactのチュートリアルを行いました。しかしまだまだWeb技術についての知識が不足していると感じているためこの企画を通してさらに学びを深めたいです。

## (2)パブリッククラウド技術の利用・構築経験

私はAWSを主軸にパブリッククラウドを利用してきました。また何度か開発を繰り返すにあたりlac(Teraform)の重要性にも気が付き、AWSで開発を行うときは必ずTerraformも一緒に扱うようにしています。

具体的な開発経験について説明します。一つは「play a catch?」というリアルタイムで見知らぬ人とキャッチボールをするゲームです。

リアルタイム通信には Photon Engine を採用し、ランキング機能は AWS EC2上でGo言語のGinというライブラリを採用しました。

初めて使うSaaSでしたがドキュメントをしっかり読み込み、無事に完成してアップロードすることができました。

一方でこの開発でも課題がありました。開発の締め切りに追われ、セキュリティ対策が後回しになってしまった点です。ランキング機能のREST APIのエンドポイントはオープンアクセスになっており、URLさえ分かれば誰でもランキングのデータを取得と登録ができるようになっていました。フリーゲームを遊びに来るユーザーに対しどの対策が適切かどうかが当時判断できなかったことが反省点です。フリーゲームでログインを求めるのはやりすぎなので、セッショントークンを発行するAPIを用意し、それを使用してリクエストを制限すればよかったと後悔しています。

ただし意識して実装した点もあります。破壊的な変更はそもそもAPIとして存在しないように設計しました。ランキングには自分のデータを教える機能と昇順でデータを返すAPIのみにして外部からは削除できないようにしました。

他にもプレースホルダを活用してSQLインジェクションを防いだり、Instance Connect以外からSSHを受け付けないようにしたりできる範囲で行っていました。

２つ目はさくらインターネットのVPSでKubernetesを構築した経験があります。

AIがコーディングをサポートするアプリを開発していたときに利用しました。このときに、自前でメールアドレスとパスワードで認証する仕組みを作りDockerで動かしていました。OSに関係なくスムーズに動くコンテナ技術に感動しました。セキュリティで意識したことは、ログイン機能ではデータベースにパスワードをハッシュ化したもので記録して情報が漏洩しても良いようにしました。また、SQLインジェクションを防ぐのはもちろんのこと、ユーザーにどこまでのレコードを読ませるかも考えていました。しかし、セッショントークンを発行してAPIにリクエストをってもらう形式を取っていたのにもかかわらず、トークンの暗号化がされていませんでした。当時はドメインを所有しておらず、IPアドレスで直でアクセスするようにしていたので暗号化がされていませんでした。これではセッショントークンは盗まれ、なりすましが容易に行われてしまいます。先月ドメインを発行したのでHTTPSで自己証明書ではなくしっかり証明してもらいセキュアな通信を行います。

また共通の課題としてマネタイズが挙げられます。

上記のようなプロジェクトを開発したものの、サーバーの維持費を継続的に支払うことが難しく、すぐにサービスを停止してしまっています。オンラインゲームの例で言えばランキング機能は廃止し、リアルタイム通信はPhotonの無料枠でまかなっているのが現状です。また、AWSなどコスト監視に関するリソースは多くありますが、学生という身分のため急な多額の請求が来た場合に払うことができない問題もあり、安定的にサービスを提供することができませんでした。

セキュリティとは少し離れた話題になってしまいますが、サービスのマネジメントやマネタイズにも強い興味を持っています。

## (3)一般のプログラミングの経験やチームでの開発経験

私には複数回のハッカソンやゲームジャムへの参加経験があり、いずれもチームでの開発を通じて、プログラミング技術と同時にチーム開発においてコミュニケーションスキルや議論する姿勢について学んできました。

私の最初のチーム開発はX（旧Twitter）で知り合った方とペアを組み、「技育CAMP」というハッカソンに参加したことです。FlutterとFirebaseを用いたモバイルアプリケーションの開発に取り組み、私はFirebaseの設定とFlutterでの通信の部分を担当しました。それまではGitを１人で使っていましたが、ブランチ戦略について学び破綻なくチーム開発のサイクルを回すことができました。また相手と気持ちよく開発できる雰囲気を作ることができ無事に完成して発表することができました。

2回目のハッカソンでは、その場で即席の4人チームを組み、UnityとC#を用いてオンラインゲームを開発しました。私は主に通信周りを担当しましたが、リアルタイム通信の設計やテスト体制の甘さから、提出物は「重すぎて使えないアプリ」となってしまいました。GitHub Actionsを使用してTerraformでデプロイの部分は作成していましたが、テストの部分を作成してなかったことが原因だと考えます。この失敗から、CI/CDやテストコードの整備がプロダクトの品質に与える影響の大きさを痛感しました。抱えてしまったことが強く印象に残っています。一方で得た学びはチーム開発の価値についてです。４人で同時に開発すると短期間で相応のプロダクトが生まれることや、ディスカッションを通してアプリそのものの価値を高められたり、１人だけの開発では得られない多くのメリットがあります。この経験を通してチームの強みを実感し、将来はチームの価値を高められるリーダーになれる人材にもなりたいと考えました。

また、「Unity1Week」ではランキング機能付きのリアルタイムオンラインゲームを開発しました（[https://unityroom.com/games/playacatch](https://unityroom.com/games/playacatch)）。ここでもソケット通信の実装に失敗し、複数人からのリクエストを正しく処理しきれなかった点や、ボールが増殖してしまうバグを抱えたままリリースした点が反省点です。アイテムが増殖するバグは深刻で、もしこれが課金アイテムであったら大きな問題でした。しかしながら、この作品は私が一番手応えを感じている作品でもあります。Youtubeにいくつか実況動画がアップロードされ心の底から作って良かったと思うことができました。ここで他人から評価されるモノづくりの面白さに気がつくことができました。

[https://youtu.be/1jJqKSErPGQ](https://youtu.be/1jJqKSErPGQ)

ボールの増殖バグについてはこの動画が参考になります。

[https://youtu.be/ASuodPh7_jk?t=797](https://youtu.be/ASuodPh7_jk?t=797)

一方で、報酬を受け取る開発経験もあります。UnityでLive2D、VRMを用いた受託開発を行い、「お金をもらってコードを書く」という責任の重みと、仕事としての開発における見積もり・成果物の品質管理の重要性を学びました。一方で見積もりのことを軽視していたことで焦った失敗があります。当初想定していた工数の１週間をプラスアルファで期日としていたのですが、実際は期日の３日前に動作するコードができ、そこからリファクタリングや調整を行いました。曖昧な見積もりは焦る原因となり結果的にコードの品質を低下させセキュリティリスクが発生する恐れがあります。

最終的には責任感を持って期日通りに提出することができたので、初めてにしてはある程度の結果だと思っています。そして更に技術以外も研鑽を積もうと意識するきっかけになったので大きく成長したと思います。

個人開発ではFlutterを用いて、資格勉強をサポートするアプリ（[https://qualification-app.web.app/](https://qualification-app.web.app/)）を作成し、以前はGoogle Playにもリリースしていました。親の名義でアップロードしていましたが、去年の夏に開発者の再審査が必要になり、その流れでアプリを閉じることとなりました。このアプリでは初めてGoogleログインやメール認証、ユーザー管理などの機能を実装し、バックエンド技術への第一歩を踏み出しました。またセキュリティの基本を知る最初のきっかけになりました。

去年の夏には、VRMとAIを組み合わせて子ども向けのプログラミング学習支援アプリを開発しました。このアプリでは、Go言語 と Ginを使ったバックエンドを構築し、ログイン機能やDB操作、JWTによる認証状態の管理、見守り機能（Nintendoの「みまもりSwitch」風）など、自分でバックエンドを構築する最初の経験になりました。特に、パスワードのハッシュ化やJWTの利用など、応用情報技術者試験で得た知識が実践に直結し、座学の重要性を改めて感じました。アプリのバックエンドはKubernetesを使用して自動で管理されるようにし、運用面も考慮しながら制作しました。

現在は、学校の防災学習で使用する防災シミュレーションを調整しています。これは私にとって、これまで学んできた技術の集大成だと考えています。地震が発生したときに人はどう動くのかを観察するために３Dゲームのようなアプリを作成しています。行動のログの機能を追加して、定量的に位置や角度、アクションなどを記録するようにしています。また、貧弱なパソコンでも動くように最適化を重ねて頑張っています。

最後に現在進行中の開発について紹介します。私は今年の春にアメリカに海外研修に行ってきました。その中でアメリカ人の同学年の情報工学が好きな友達ができ、今まさに何か一緒にできないかと構想をねっている段階です。コミュニケーションは英語で行い、相手の背景を理解して協力しています。そして持っている文化や宗教は違えど、同じ情熱を持つ人と協働する喜びを感じています。日本や世界には様々な人がいますが、対話を通して理解し合い切磋琢磨する姿勢を持ち続けたいです。

これらの経験を通して、一人でローカルで完結する閉鎖的な開発から、多くの人と協働し、グローバルな規模でデータをやり取りする開発へとシフトしてきました。こういった変化からセキュリティに対する学ぶモチベーションが非常に高くなっています。

## (4) コンテナ技術の利用経験

コンテナ技術に関してもまだまだ学習中の段階です。

これまでにKubernetes、AWS ECSおよびEKSを用いたハンズオンを複数回経験しました。Udemyで「[Kubernetes Hands-On - Deploy Microservices to the AWS Cloud](https://www.udemy.com/course/kubernetes-microservices/)」([https://www.udemy.com/course/kubernetes-microservices/](https://www.udemy.com/course/kubernetes-microservices/))の講座を参考にし、マイクロサービスのアーキテクチャのサービスの構築を行いました。構築をする中でAPIゲートウェイの役割や各サービスのスケーラビリティ、サービス同士の疎結合の重要性を学びました。またマイクロアーキテクチャとコンテナ技術の相性が良いことを学んだので次回のバックエンドでも参考にしようと考えています。

実践に関して言えば夏に参加したプログラミングコンクールでは、コンテナを作りコンピュータ上のKubernetesでホストしています。しかしながら動作するレベルに留まっており、まだまだ最適化や堅牢にするなど改善の余地があると感じています

また、応募課題に取り組むにあたりもっとコンテナ技術を知りたいという気持ちが湧いたので、早速課題Q4で使いました。課題Q4では特定のバージョンのApacheサーバーを使用する必要があり、攻撃をするために環境を作る必要があったため、コンテナを利用するのにうってつけの場でした。これまで利用する機会は少なかったのですが、課題を取り組むのかで実際に手を動かして試してみました。

これらのコンテナの経験はあくまでも個人や検証用の範疇にすぎません。実際の社会で運用されるものはこれらに比べると規模感や堅牢さが桁違いです。また障害対応など個人の小さなサービスでは起こりにくいことも頻発するでしょう。私は改めてこの点を大きな課題と捉え、今後はより実践的な場でコンテナ技術を扱い、運用やセキュリティといった観点でも深く学んでいきたいと考えています。セキュリティキャンプでの学びを通じて、こうした技術を現実のシステム設計に応用できる力を養いたいと強く思っています。

## (5) CI/CD 環境のセットアップ・利用経験

私は個人開発において GitHub Actions および Jenkins を用いた経験があります。GitHub Actions では、主にmainブランチへプッシュされたのをトリガーとして Dockerイメージをビルド・デプロイしてKubernetsでバックエンドがアップデートされるようにしました。またチーム開発においてTerraformを使用していたときも同様にmainブランチから新しくサービスを作成するようにしていました。これらの経験を通して環境変数の管理、ジョブの並列実行、シークレットの扱いなど、CI/CDを構成するうえで必要となる基本的な知識を学びました。

また、過去にUnity を用いたゲーム開発を行っていた際には Jenkins を導入し、mainのWebhookを使用して自動ビルドを行う仕組みを構築しました。余っているノートパソコンを自宅サーバーとし、自動ビルドおよび実行ファイルの保存を行いました。現役のゲームプログラマーの方にアドバイスを頂きながら、ビルドがされたらSlackやメールに通知が飛ぶように設定してより実務寄りの構成にもチャレンジしました。Jenkinsを扱うときにはログイン機能について調べた経験があります。誰でも設定ファイルを変更できないように権限を設定して多数の人間がアクセスする想定で作成しました。ここで認証と認可について意識して取り組むことができました。それまではGitHub Actionsのみを使用していましたが、オンプレミスで動作するOSSのJenkinsを使うことでCI/CDの柔軟性や拡張性を深く実感しました。

一方で、CI/CD の「CD (Continuous Delivery/Deployment)」の部分に関しては学び実践することができましたが、「**CI（Continuous Integration）**」の部分に関する知識が不足しています。テストコードの記述やユニットテストの自動化にはまだ取り組めておらず、テストをせずにデプロイが行われる脆弱な構成となっているのは大きな課題です。また、応用情報技術者試験を通じてウォーターフォールやアジャイルといった開発手法については学習したものの、実際に開発手法を体験した経験は乏しいのも問題です。

まずはCIについての知識を深め、開発プロセスと密接に結びついた運用を実践することで、プロダクトの品質保証を意識した開発ができるようになりたいと考えています。

---

# ■ Q.3（あなたの感心・興味について）

私はウェブサイトにアクセスする時に利用するDNSが、攻撃に利用されてしまうと大きな脅威になってしまうことに関心を持っています。とりわけ **DNS リフレクション攻撃** は、わずか数十バイトの要求が十倍近い応答に化ける点とDNSが踏み台にされている点の２つの特徴があります。。DNSリフレクションはDNSのレスポンスが重いことを利用します。送信元のIPアドレスを攻撃するコンピューターのものに書き換えたパケットをDNSに投げ、相手の帯域幅を圧迫させる攻撃です。

現実で例えると嫌がらせをしたい近所の人間の住所を使って、勝手に大量の資料請求を行い、大量の資料がその住民に届くようにする攻撃です。

上記の説明が教科書でよく書かれるものですが、この課題に取り組むにあたり内部の仕組みを深く知り対策まで知りたいと思いました。そのためローカルで実験をして確かめていきたいと思います。

実験環境の構築の手順に説明します。これは攻撃の実験のためパブリックなDNSサーバーを決して使いません。自分の所有するコンピューター内で完結する環境を作ります。テストの結果からも外部ネットワークへのパケット流出はしていなかったことも確認できました。

また万が一のために使用するアドレスは私自身が所有するものとします。事前にCloudflareでドメインの名前解決を停止させておきました。

(RFC 2606によるとexample.comはテスト用に空けられているドメインでした。実験開始時はexample.comは誰かが取っているドメインのはずだから自分の所有しているものを使ったほうが良いだろうと考えていました。)

実験手順については添付したファイル「実験手順.md」を参照してください。

添付した「DNS_reflection」というフォルダに、wiresharkのログファイル、攻撃用のスクリプト、実施時の動画があります。

実験の結果をまとめます。

攻撃者となるホストOS（IPアドレス: 192.168.11.25）から、送信元IPアドレスを被害者マシン（192.168.11.100）に偽装したDNSリクエストを送信すると、DNSサーバはそのIPアドレスに対して約1200バイトのレスポンスを返すことが確認できました。

(添付した dns_reflection.pcapng をWiresharkで確認して下さい。)

また、正規のDNSリクエストとの比較のため、両マシン上でそれぞれdigコマンドを使用してリクエストを行いました。その結果、digコマンドを用いた場合は送信元IPアドレスが実行したマシン自身のものであり、レスポンスの宛先アドレスもマシン自身のものとなっていました。

(添付した normal_request_by_dig.pcapng を参照)

また送信元IPを偽装したDNSリクエストパケットと、digコマンドで生成した正規のリクエストパケットとの間に見られる差異について注目しました。大きな違いは送信元のMACアドレスです。ip address show コマンドの結果より、被害者のコンピューターのMACアドレスは「52:54:00:6c:4a:28」、攻撃者のコンピューターのMACアドレスは「6e:80:21:1b:22:f0」であることが確認できました。偽装リクエストのパケットを確認すると、送信元IPアドレスが被害者のものに書き換えられているにもかかわらず、送信元MACアドレスは攻撃者マシンのものがそのまま使われていました。

一方でDNSからのレスポンスパケットでは、宛先のMACアドレスが被害者マシンのものになっていました。

最後に実験結果から考察を行います。

まずDNSリフレクション攻撃手法について気づいたことについてまとめました。

1. 送信元IPアドレスは簡単に書き換えられる
2. リクエストのデータ量よりはるかにレスポンスのデータ量が大きい。今回の場合だとリクエストの10倍以上になった。
3. 攻撃側も通信に帯域幅を使うので、リクエストが小さければ小さいほど単位時間あたりに攻撃できる回数が増える
4. DNSプロトコルに限らず上記の条件を満たすプロトコルやシステムがあれば置き換えが可能。例えば**memcached　というサービスも大きなレスポンスを返すので悪用された**
5. 複数のDNSを利用して並列して攻撃が可能
6. レスポンスを待つ必要がないので返ってくるのを待たずに並列して攻撃が可能
7. 攻撃者が防衛側に比べ圧倒的に有利である。
8. MACアドレスまでは詐称しない。
9. EDNS0を有効にすれば効率よく攻撃ができる

しかしながらEDNS0について解決できなかった問題がありました。それはスクリプト上で4096バイトまで応答に使用可能であることを教えているはずなのに1200バイトあたりを超えると80バイトほどのレスポンスになったことです。DNSの設定なのか通信の問題なのかまでは踏み込むことができませんでした。

次にDNSリフレクションの対策法について自分で考えたことについてまとめます。

1. DNSのレスポンスを受け入れるドメインをホワイトリストで管理する

不適切  → サイトの殆どが使えなくなり、セキュリティの部門に問い合わせが多発し業務にならない。

1. 異常なトラフィックを検知した場合は送信元を動的にブロックする

不適切 → 送信元はDNSサーバーになっているためブロックするとインターネットがほとんど使えない。

1. 詐称されたパケットは送信元のMACアドレスと宛先のMACアドレスが一致ていないことを利用してブロックする

不適切 → UDPはステートレスなプロトコルである。

1. DNSサーバーにDNSSECを導入する

やや不適切→乗っ取りを防ぐことで攻撃者に武器を渡さないことにはなるが、今来ている攻撃に対処するものではない。

自分で４つ対策を考えましたがやはり限界があると考え調査しました。

調査をすると末端の会社や個人だけではDNSリフレクション攻撃に根本から対処できないということが分かりました。例えばこの記事によるとインターネットの上流側、つまりプロバイダーの段階で止めるという対策を行っています。

[https://www.sojitz-ti.com/focusarea/column/ddos_shutout_netscout/](https://www.sojitz-ti.com/focusarea/column/ddos_shutout_netscout/)

他にもDNSのサーバー側で対策をする手法も見られました。CloudflareではANYリクエストを禁止にすることでDNS Reflection攻撃を和らげようとしています。

[https://blog.cloudflare.com/ja-jp/rfc8482-saying-goodbye-to-any/](https://blog.cloudflare.com/ja-jp/rfc8482-saying-goodbye-to-any/)

この結果からWebサービスあるいはインターネット全体の健全さというのは、一個人や団体だけの努力では実現せず、インターネットに参加する者一人ひとりがセキュリティーの重要性を意識しセキュリティの向上に務めることによって実現されることを学びました。一つの視点だけでは問題に対処することは難しく、複数の観点から行動を行うことで改善につながります。

例えば教育の視点からもアプローチをしていくことが必要だと思います。エンジニアが技術力を高め、システムをより安全にしても使う人間が脆弱だった場合、攻撃者にそこを狙われてしまいます。一つの穴を完璧に塞いでも他の穴が何も対策されていなければ簡単に侵入されてしまいます。ですからセキュリティ教育をし、非エンジニアの人もある程度の知識を持っていくことが大切です。

最初は技術について調べ、検証し結果を示すだけだと考えていましたが、最終的に私達がセキュリティに向き合う姿勢について考えさせられるとは思いもしませんでした。そしてこのような攻撃を防ぐために裏方で頑張っているエンジニアの存在を初めて認識しました。私がこのセキュリティキャンプに修了した暁には、インターネットを支える自覚を持ち人々から脅威を守る一員になりたいと考えます。

---

# ■ Q.4（Web に関連する脆弱性・攻撃技術の検証）

「Top 10 web hacking techniques of 2024」( https://portswigger.net/research/top-10-web-hacking-techniques-of-2024 ) は、Web に関するセキュリティリサーチャーの投票により作成された、2024 年に報告された興味深い Web に関する攻撃テクニック 10 選です。この Top 10 中の事例の中で、興味を持てたもの 1 つに関して、以下を説明してください。

(1) 事例の概要
(2) 攻撃手法の詳細
(3) その他その事例に関して感じたこと・気がついたこと
なお、本設問では、関連する仕様や攻撃の適用可能な条件についての詳細な理解が垣間見えるような記述や、理解を深めるために行ったこと（例: ローカルで行った再現実験等）に関する記述を歓迎します。

## (1)事例の概要

Apache HTTP Server は、多数のモジュールで構成されているOSSです。しかしこの大量のモジュールがあるがゆえに、**モジュール間で共有される構造体のフィールドに一貫性がなく脆弱性が生まれています。意図的に構造体のフィールドの意味の食い違いを起こすデータを与えることで不正な挙動を引き起こすのConfusion Attack**です。Orange Tsaiさんがこの性質に気が付き、具体的な攻撃手段を「**Filename Confusion**」「**DocumentRoot Confusion**」「**Handler Confusion**」の３つに分類して公表しています。これらの脆弱性は9つのCVEにも登録されており、非常に致命的な問題となっています。このアイディアを利用した攻撃手法では、ディレクトリトラバーサルと任意コード実行とXSSを仕掛けることができるので、攻撃の自由度の高い脆弱性になっています。

## (2) 攻撃手法の詳細

最初の「Filename Confusion」は`mod_rewrite` など一部モジュールは `r->filename` を URL として扱い、他のモジュールはファイルパスとして扱います。攻撃者がリクエストに「`?`」やエンコードした区切り文字を紛れ込ませると、一方のモジュールはその後ろを無視し、もう一方は含めたまま処理します。その結果、本来拒否されるはずのファイルにアクセスできます。またスクリプトを画像としてアップロードし、http://server/upload/1.gif%3evil.php

 のようなリクエストを当てると、サーバーは GIF と判断したまま 1.gif を PHPとして実行されます。その結果攻撃者がバックドアを仕掛け被害が広がる可能性があります。

次に「**DocumentRoot Confusion**」についてです。Apacheのhttpd.confにDocumentRootとRewriteRuleがあるときに、アクセスが合った場合に両方のルールにマッチするパスのファイルを開こうとします。そこでRewriteRuleを狙うことで任意のファイルにアクセスしようとするのがこの問題の肝です。これを使用して内部で実行されるcgiやPHPのソースコードを不正に見ることができます。もしもパスワードやユーザーの個人情報が記録されているファイルがダウンロードされたら大きな損害が生まれます。　

最後の「**Handler Confusion**」はファイルが呼ばれたときに実行される動作のApacheでの表現を悪用したものです。AddHandlerとAddTypeという設定が内部では別々のフィールドを指しているが、処理の間に上書きされることでAddHandler であろうと AddType であろうと最終的に同じモジュールを呼び出す問題の原因です。例えば、HTTPサーバーにエラーが発生したときに、本来は停止するはずなのに戻り値の処理の問題で処理が続き、本来はPHP として処理されるはずのファイルがテキストとして処理されてしまう問題が記事にあります。その結果、レスポンスにPHPのコードがそのまま返されるのでソースコードの内容が攻撃者にバレてしまいます。

参考文献　[https://blog.orange.tw/posts/2024-08-confusion-attacks-en/](https://blog.orange.tw/posts/2024-08-confusion-attacks-en/)

## (3) その他その事例に関して感じたこと・気がついたこと

記事の1-1-1を実際にローカルで試してみました。([https://blog.orange.tw/posts/2024-08-confusion-attacks-en/](https://blog.orange.tw/posts/2024-08-confusion-attacks-en/))

添付したapache_confusion1-1-1に環境を整えたので参照してください。

また「実験手順.md」に手順と攻撃をしたときのログがあるので参照してください。

記事には記載されていませんでしたが、**httpd.confに `AllowEncodedSlashes On` を記述しないと攻撃が行えません**でした。これはエンコードされたスラッシュ（`%2F`）をデコードして扱うために必要でした。

結果として、通常のリクエストでは公開しているprofile.ymlを返し、直接アクセスしようとすると404が返ってきますが、不正なリクエストの方ではsecret.ymlの内容が出力されています。実際のcurlコマンドを使用して出力されたログについては添付した「実験手順.md」を参照してください。

記事の1-1-1以外の攻撃も試して見ましたが、コンテナでApacheにPHPを扱わせるところでつまり、どうしてもうまく行きませんでした。Apacheにそもそも不慣れだったということもあり、私が行えたのが1-1-1だけでした。今後の展望としてHTTPサーバーの仕組みを実際に自分のプロダクトを配信することを通して学びたいと考えています。今まではindex.htmlのみを配信するだけでしたが、リソースのアクセス制限やリダイレクトの設定を行い、さらに知識をつけてConfusion攻撃に再度挑戦したいです。

今回のApacheのConfusion攻撃を調べ実験することで次のことを考えました。

まずセキュリティのリスクに気がつくことはとても難しいことです。この問題を再現するためにDocker上にApache 2.4.58を立て、実際にRewriteRuleの設定をして実験を行いましたが、再現するのに苦労しました。**攻撃が成功する条件や挙動はバージョンや設定によるので、手元のApacheの挙動を一見して脆弱かどうか判断するの難しいことなんだと実感しました。内部処理に対する深い理解がなければこのセキュリテイのリスクに気づき対策できないことは危険だと思いました。**

そしてこの問題の最も重要な点は脆弱性の本質です。この脆弱性は「構成ミス」や「設定ファイルの誤り」ではなく、**ソフトウェアにおける内部設計の一貫性のなさにあります。特に**モジュール間で共有される構造体フィールドの意味的な食い違いがあるので問題が発生しています。これはApache特有の問題というよりも、**長期間運用され、複数人・数多くのモジュールで構成される巨大なソフトウェア一般に存在するリスクだと思います。**

この問題に対策するためにはCI/CDの環境を整えたり、構成ドキュメントを継続的に整備することが大切だと考えます。実装時に各モジュールの知識が不足していたエンジニアが要因の一つなので、しっかりと知識を参照できる場所とテストの体制が必要です。

また自分たちが普段使用するライブラリやコンポーネントを組み合わせる部分でも同じような脆弱性が生まれる可能性が十分あると考えます。たとえば、開発標準や設計指針が整っていない状態で長期間リファクタリングなどを繰り返せば、当初の設計から変化して一貫性のなさが生まれます。この脆弱性は対岸の火事ではなく、自分事であるという学びを得ました。

これまで私はCVEの情報を見るときは「このサービスは脆弱なんだ」と思うだけ終わらせていました。今回の調べたことを通じて、脆弱性のニュースを見る目が変わりました。本当に重要なのはその脆弱性の問題の本質を捉え、どう自分が運用してるプロダクトに対策をするかを考えることです。これからはIPAの脆弱性のメールを流して見るだけではなく、好奇心を持ってリサーチをしていく姿勢を大切にしたいです。

---

# Q.5（パスキーに関連する標準や実装の調査）

## (1) 任意のパスキーが使用されているサービスを実際に利用して使用感を調査したうえで、技術的・運用的・UXの観点から、あなたが課題だと思う点を述べてください。また、その解決策についても考えてください。

私はAWSのダッシュボードへのログインをパスキーで試してみました。

最初に技術面に関して説明をします。

パスキーの最大の技術的課題は**プラットフォーム間の互換性の乏しさ**です。現在のパスキーはそれぞれのプラットフォーム（Google、Appleなど）に強く依存している形で実装されているので、使える環境と使えない環境で分かれています。例えば私のメインPCのOSはLinuxでOSレベルのサポートがないので、Google Chrome以外のブラウザ（例：Firefox、Brave）で使うことができません。ChromeにはGoogle Password Mangerがあるのでパスキーは利用できるのでAndroidとの同期は容易です。しかし開発時にFirefoxやBraveなど複数のブラウザを利用する場合や、Chromeが使えない社内環境である場合など考えられます。またAndroidとiPhoneを併用するときにはそれぞれ別のパスワードマネージャーが推奨され、結果としてパスキーが分散して保存され管理が大変になる可能性があります。その際にパスキーの同期に不便を感じます。

ユーザー側ができる改善策としては1Passwordなどクロスプラットフォームに対応したパスワードマネージャーを使用することです。しかしながら有料のサービスであるので全てのユーザーが使える状況ではないです。

一方でFIDOアライアンスなど開発を行う企業や団体でできる改善策は多くあると思います。例えばクロスプラットフォーム対応の認証器の普及やFIDO仕様の整備をしたりAPIを共通化すること互換性を担保することができます。

総じて現在の状況ではブラウザやOSなどのプラットフォームが固定化されてしまう課題があります。

次に運用面に関する課題を説明します。

同期型のパスキーはOSやブラウザに紐づくパスワードマネージャーに保存されますが、そのマネージャー自体のログイン認証には多くの場合**依然としてパスワードが必要です。マネージャー**を乗っ取られ使えなくなると完全にログインができなくなります。これを解決するには利用者はログインの時のパスワードを長く複雑にしていくことが必要です。サービスの運営者はリスクベース認証を導入するなど第三者にログインされにくいよう対策することが必須です。

また、パスキーの他サービスへの移行がほぼ不可能であることも課題です。例えばGoogle Password Manager からAppleに移行するなどは現在できません。そのため一度各サービスにログインしてパスキーを再登録する必要があります。これを改善するには移行のAPIを共通の規格化することが良いと考えます。実際に調べてみるとFIDO アライアンスが「**Credential Exchange Protocol」という草案を出し、実行に移そうとしています。**([https://gigazine.net/news/20241016-fido-alliance-credential-exchange-protocol/](https://gigazine.net/news/20241016-fido-alliance-credential-exchange-protocol/))

最後にUX面に関しての課題を説明します。

AWSにおけるパスキーによる認証は**従来の二段階認証を置き換える形で提供されていました。まず**アカウントIDとユーザー名とパスワードを入力した後に二段階認証としてパスキーを使用しました。本来パスキーは所有と生体か知識を使って認証を行う一段階二要素認証ですが、パスワードが残ったままでは、ただ間が増えた感じが否めません。多くても数十文字程度の文字列よりも公開鍵、秘密鍵で生成される情報の方が遥かに複雑であるので完全にパスキーへ移行するべきだと考えます。

また一般の利用者からの視点で考えると、パスキーは一般には浸透しておらず、認証方式を自由に選べる際にすでに知っているパスワード方式やSMSでの認証を選択してしまう恐れがあります。良くわからないから取りあえず避けておこうというユーザーを防止するためには、各認証方式のメリット・デメリットを**学校教育や社内研修などを通じて教育する活動も必要だと考えます**。ユーザーに慣れ親しんでもらうためには、サービスの運営側が**積極的にサービスに組み込み、ユーザーに実際に触れてもらう機会を増やすことも重要だと考えます。**

またAWSでパスキーを登録するときに画面の奥深くまで行く必要がありました。IAM > ユーザー > 自分のユーザー名 > MFA デバイス割当　に遷移してパスキーを設定する必要があります。これは他のサービスでも言えることですが、ログイン情報の操作は使われる頻度が少ないので画面の奥の方に置かれてしまいます。パスキーの利用を促すのでならばログイン後に**ポップアップなどでパスキー登録を促す導線を確保することが有効だと思います。**

## (2) 認可と認証の違いについて、例を挙げて説明したうえで、OAuth 2.0 や OpenID Connect（OIDC）とパスキーの仕様（WebAuthn）の関係について説明してください。

認証（Authentication）は、システムを利用しようとする者が「誰であるか」を確認するプロセスです。一方で認可（Authorization）は、認証された者に対して「どのリソースに、どのような操作が許可されているか」を制御するプロセスです。

例えばID基盤という複数のサービスの認証機能を一つにまとめるという概念があります。複数のサービス（サービスA・B・C）があるとします。Adminはすべてのサービスにアクセスできますが、ゲストはサービスCのみにアクセスできるとします。Adminのダッシュボードには全てのサービスを利用できるように各サービスへのリンクが表示されますが、ゲストのダッシュボードにはサービスCへのリンクしか表示されないといったことができます。

ログイン時にはまずパスワードなどを使って認証が行われ、その後にそのユーザーの権限に応じてアクセスできるリソースが決定される、これが認可です。

現実で例えると、カジノの受付で会員カードを提示して本人確認を受けるのが「認証」、その結果としてステータスがVIPであればVIPルームに入室できるようになるのが「認可」にあたります。

次に、OAuth 2.0、OpenID Connect（OIDC）、パスキー（WebAuthn）の関係について説明します。

まずこれらが果たす役割について説明します。

OAuth 2.0は、本来「認可」を行うためのプロトコルです。ユーザーはGoogleなどの認可サーバーに対して認可リクエストを送り、そのアカウントの認証が行われた後、アプリに対してアクセストークンが発行されます。このトークンを使ってアプリはリソースサーバーにアクセスし、本人が管理するデータを利用することできます。例えば、Google Photo と連携をする場合には本人が保存した画像を取得するといった感じです。

ただし、この仕組みを応用して「OAuth認証」として使う方法もあります。これは「もし本人だったらその人のプロフィールにアクセスできるトークンを発行できる。」ということを利用してアプリでログイン処理を行うことです。本来OAuthは認可だけを行いますが、IdP(Identity Provider)で認証したことを利用して認可プロトコルを認証目的に流用しています。

一方でOpenID Connect（OIDC）はOAuth 2.0を拡張し、ユーザーの「認証」機能を拡張したプロトコルです。OAuthに加えて、IDトークンとUserInfoエンドポイントが定義されており、IDトークンにはユーザー識別子（`sub`）、発行時刻、トークンの受領者、署名情報などが含まれます。これにより、リソースへのアクセスと同時に「誰がログインしているのか」という情報を安全にやり取りできるようになります。

純粋なOAuth認証ではトークンが入れ替えられても気づくことができなかったのですが、IDトークンのおかげでアプリはなりすましを検知することができます。

WebAuthnはFIDO2に基づく公開鍵暗号方式による「認証」プロトコルです。パスキーは、ユーザーごとに生成された公開鍵・秘密鍵ペアに加え、ドメイン名やユーザー識別子といったメタ情報を含んだものであり、ブラウザやOSに統合された認証手段として機能します。パスワードレスで安全にログインできるほか、ユーザーは指紋認証や顔認証などの生体情報を用いてローカルで秘密鍵をアンロックし、認証をします。

最後に、これらをどのように組み合わせることができるかについて説明します。

WebAuthnによるパスキーは、OAuthやOIDCにおける「IdP」の認証手段として利用することができます。たとえば、Googleアカウントへのログイン時に従来はパスワードが使われていましたが、この部分をパスキーに置き換えることが可能です。OAuthやOIDCは、ログイン済みアカウントに対してアクセストークンやIDトークンを発行するプロトコルであり、その前段階の「本人確認（認証）」において、より安全にかつ便利に認証できる手段としてパスキーを利用することができます。

## (3) 従来の認証方式（パスワード、OTP、SMS認証など）と比較した場合、パスキーのメリットとデメリットを述べてください。

従来の方式と比べて見えるパスキーのメリットについて説明します。

第一にパスキーはユーザーのリテラシーに依存しにくいメリットが挙げられます。従来のパスワード認証では、ユーザーが脆弱なパスワードを作成したり、複数サービス間で使い回すといったヒューマンエラーがセキュリティリスクに直結していました。ユーザーが関与しない形でランダムな鍵ペアが生成され、しかも各サービスに対して一意な認証情報が発行されるため、漏洩や使い回しによるリスクを減らすことができます。

第二にフィッシング詐欺への対策にもなります。パスキーはWEBサイトのドメイン情報をメタデータとして保存しているので、ドメインが一致した正規のサイトでしかパスキーが使えません。現在のパスワードマネージャでもドメインをチェックして自動入力をする機能はありますが、ユーザーが自らパスワードを調べて入力してしまうリスクがあります。SMSも同様に偽物のサイトに認証コードを入力してしまう問題があります。

第三にパスキーは情報の流出にも強いという特性があります。パスワードではCSVファイルで平文のまま保存しそれが流出したら誰でもログインができてしまいます。しかしながら、パスキーでは秘密鍵はTPMなど安全な場所に保存されるおかげで、ネットワークにデータが流れたりするといったことがありません。また純粋なOAuth認証ではトークンを盗まれると他のサービスに勝手にログインされてる可能性がありますが、パスキーはサービスごとに秘密鍵と公開鍵のペアを作成するので仮に情報が流出しても他のサービスにログインされないメリットがあります。

第四にユーザーの存在を検証できるという利点があります。従来のパスワードやSMSでは辞書型攻撃などスクリプトを用いて遠隔地から認証を試みられてしまうリスクがありますが、パスキーではデバイスの前に本人がいないとロックが解除できない仕様になっています。例えばCTAP2で「Hybrid」通信方式として定義されているクロスデバイス認証では、QRコードで通信用の暗号鍵などの情報をクライアントからスマートフォンに渡した後、スマートフォンがBLE(Bluetooth Low Energy)通信を利用してBLEトンネルサーバとの接続情報を送信し、チャレンジや署名データのやり取りが行われます。BLE通信が必須なため、認証器と端末が物理的に近くにないと認証をすることができません。

運用面に関しても大きなメリットがあります。例えば攻撃者による乗っ取りがしづらくなっています。SMSを使った認証ではSMSスワップという手法で乗っ取られることがあります。また電話番号は使い回されるので、ログイン情報を変えておかないと他の人にSMSが届く恐れがあります。また移行に関してもメリットがあります。従来のTOTP方式での認証アプリの多くは、サーバではなくデバイス内にのみシークレットを保存するので新しいデバイスに乗り換えるたびに、すべてのサービスについて登録する必要があります。デバイスを紛失するとログインする方法を完全に失ったり、復旧用の鍵が漏れる恐れがありますが、パスワードマネージャでパスキーを管理するので移行が簡単です。他にも会社の調達の面でもメリットがあります。例えばセキュリティキーはログインする社員一人ひとりに支給するする必要があります。人数が大きくなればなるほど購入する費用が大きくなり負担となります。また物理的な物になので汚損や故障などがあれば買い直すコストも発生します。一方パスキーは元々あるコンピューターで認証できるので新たに調達することも少ないです。

運用面に関しても利点があります。

一つは従来の、TOTPやSMS認証では新しい端末に切り替える際に再登録が必要です。SMSに関しては電話番号は使い回されるものなのでログイン情報を変更しておかないと他の人に認証のSMSが行ってしまう恐れがあります。一方パスキーはクラウド同期されるため、端末の紛失や買い替えの際にも、パスワードマネージャにログインをするだけなので、同じプラットフォーム上での他の端末に切り替えはスムーズに行えます。

２つ目にハードウェアの調達のコストがかからない点です。セキュリティキーのような物理デバイスは、企業において人数分の調達や管理が必要となり、費用と手間がかさみます。セキュリティキーなどは、経年劣化や汚損、破損が考えられるので再度購入する必要もあります。しかしパスキーはTPMなど要件を満たしていれば既存のPCやスマートフォンをそのまま使うことができます。

パスキーはUXの面でもメリットもあります。

まず従来の二要素認証では、所有認証（デバイスの所持）と知識認証（PINやパスワード）または生体認証の入力を、別々の操作で行う必要がありました。例えば、ワンタイムパスワードを入力するためにGoogle Authenticator を起動して再度Webサイトに入力するときがあります。しかしパスキーでは、これらを**一度の操作で同時に認証できる**ため、ログイン時にアプリを切り替えるなどの煩雑な手順が不要になります。

加えてID連携のデメリットも克服します。ID連携ができるサービスでは、複数のIdPのサポートをしていることは珍しくありません。その時に自分がどのアカウントで登録したかを思い出せず混乱することがあります。しかしパスキーであれば、プラットフォームが提示するポップアップに従うだけで済むため、ユーザーの判断負担が大幅に減ります。

他にも、パスキーの**ポップアップ形式での認証**は、マジックリンク方式よりも優れている点があります。マジックリンクでは、メールからリンクを開くとアプリ内ブラウザで意図しないセッションが確立されることがあり、ログインが失敗することがあります。これに対してWebサイトの画面のまま認証を行うので、セッションの一貫性を保ったまま認証が行えます。

さらに、**ログイン時だけでなく、アカウント復旧時にもUXが向上します**。

パスキーはGoogleアカウントやApple IDなどのいつも使うアカウントのパスワードマネージャーで同期されるため、復旧時にはいつも使っているアカウントで再ログインするだけでよくなります。従来の認証方式ではどのメールアドレスを使っていたのか忘れて復旧できないといったことがありました。

ここでよく似ている生体認証とパスキーの違いについて比較を行いたいと思います。

生体認証は「この端末の持ち主であること」を検証するだけで、アカウントそのものと直接は結びつきません。一方パスキーは、事前に生成された鍵ペアに基づいて「このアカウントの持ち主であること」をサーバが認識できます。

生体認証は基本的に**その端末だけで使える認証情報**ですが、パスキーは**複数のデバイス間で同期**され、他の端末からのログインにも使えます。生体認証は「補助的な本人確認手段」として後から追加されますが、パスキーは最初から「メインのログイン手段」として機能できます。生体認証は柔軟な一方、**セキュリティ設計の重責を開発者が担う**必要があります。対して、パスキーは**標準仕様に基づくため、安全性と相互運用性が担保されやすいメリットがあります。**

次にデメリットについて述べていきます。

パスキーにおける最大の課題は、依然として技術的に発展途上である点です。SDKやAPIの成熟度が不十分であり、すべてのプラットフォームで自由に実装・運用できる状況には至っていません。パスキーの認証に必要なミドルウェアが整っていない環境では利用が困難です。

また、従来の方式ではなかった特性が問題につながる場面もあります。パスキーは一つのサービスに対して複数個登録ができるため、万が一攻撃者にログインされてしまうと、勝手にパスキーを作登録される可能性があります。この場合、パスワードの変更だけでなく不正に登録されたパスキーを特定して削除する必要があります。

また技術面でも課題があります。パスキーは利用するWebサイトのドメイン（RPID）を基に使用するキーを判断しているので、サービスを統合するときに煩雑になるときがあります。RPIDには表示中のWebサイトのドメイン（またはeTLD+1までのドメイン）しか設定できないため、M&Aやサービス統合によってドメインが変わる場合、`related-origin`の設定など追加の構成変更が必要になります ([https://web.dev/articles/webauthn-related-origin-requests](https://web.dev/articles/webauthn-related-origin-requests))

さらに、サービスの設計において「記憶情報」や「生体認証」による認証を明示的に求める場面では、パスキーの柔軟すぎる仕様がかえって問題となることがあります。パスキーは端末側の機能に応じてPINや生体認証などの手段を選択しますが、サービス提供者が特定の手段（例：必ず生体認証）を強制することはできません。

根本的な問題として、パスキーは各プラットフォームと認証ベンダーへの依存度が極めて高い点が挙げられます。プラットフォーム側に脆弱性が存在した場合、その影響は全ユーザーに及ぶ可能性があります。確かに、リスクベース認証や多要素認証を導入することで一定の緩和は可能ですが、「絶対に安全な認証方式」というものは存在せず、パスキーも例外ではありません。

特にパスキーは同期が前提となっているため、同期されていない状態では非常に使い勝手が悪く、事実上機能しません。一つのデバイスのみにパスキーが保存されていた場合、端末の紛失はアカウントへのアクセスができなくなることと同義です。悪意ある第三者が利用者がサービスにアカウントへログインさせないことが目的だった場合には、この性質が悪用されるかもしれません。

さらに、パスワードマネージャとサービス間での同期に不整合がある場合、認証エラーが発生することがあります。たとえば、ユーザーがパスワードマネージャ側でパスキーを削除しても、サービス側に公開鍵が残っていればエラーとなり、逆もまた然りです。このような不整合を防ぐためには、Signal API等を用いてサービス側とパスキープロバイダ間で状態同期を取る必要がありますが、現時点で対応しているプラットフォームやマネージャは限られています。

## (4) 従来の認証方式（パスワード、OTP、SMS認証など）で提供されたWebアプリケーションにパスキーを実装するとき、サーバー側でどのような変更が必要ですか？

パスワードやOTP、SMS認証といった従来の認証方式を用いていたWebアプリケーションにパスキーを導入する際には、サーバー側にいくつかの重要な変更が必要です。

まず最も基本的な変更として、ユーザーごとの**公開鍵の保存**が求められます。パスキーはFIDO2およびWebAuthnの仕様に準拠した公開鍵暗号方式を採用しており、ユーザーが新たに認証器を登録するたびにサーバーはその公開鍵を記録しておく必要があります。従来のパスワード認証では、一人のユーザーに対して一つの認証情報（パスワード）が基本でしたが、パスキーでは複数のデバイスから複数の公開鍵が登録されることを想定し、データベースの構造を「ユーザー：パスキー = 1：多」の関係に対応できるように変更する必要があります。

次に、**チャレンジ（challenge）の生成と管理**も不可欠です。WebAuthnでは登録時および認証時に、サーバーがランダムなチャレンジを生成し、クライアント側で署名させ、それを検証するという一連の流れで安全性を担保しています。このチャレンジは一時的なものであり、セッションまたはキャッシュで一時的に保存し、後でレスポンスと照合できるようにしておく必要があります。

さらに重要なのが、**レスポンスの検証処理**です。ユーザーが提出する認証レスポンスには、署名データだけでなく、認証器のIDやカウンター、署名対象のデータなどが含まれており、これらを正確に検証しなければなりません。この処理は単純なパスワード照合とは複雑で、実装する人がパスキーの仕様の理解が不可欠です。

そのため、多くの開発現場ではこの部分を自力で実装するのではなく、AWS CognitoのようなSaaSを使用するのがコストとセキュリティの面から考えても合理的だと言えます。

フロントエンド側でも変更が必要です。特にモバイルアプリの場合は２つの実装方法があります。一つはWebサイト上でログインを行いアプリでその結果を受け取る方法です。画面が遷移するのでログインの体験を悪くしてしまうデメリットあります。もう一つは各OSのネイティブのAPIを呼び実装する方法です。デメリットとしてはそれぞれのプラットフォーム事に対応することがあります。その一方でネイティブの動作を提供するのでUXが向上します。

## (5) あなたが企業のエンジニアだった場合、経営陣にパスキーの導入を提案するとしたら、どのようなポイントを説明しますか？

企業の経営陣にパスキーの導入を提案する際には、「利益を生むか」「リスクを下げられるか」「競争上の優位性を得られるか」という観点を重視する必要があります。技術者同士でよくやってしまいがちな、技術的な理想やロマンではなく経営する立場からものを考えて提案するべきです。

まず、**サポート業務の削減によって人件費が大幅に下がるということを強調します**。理由は、現状のログイン方式では「パスワードを忘れた」といった問い合わせが非常に多く、それに対するカスタマーサポートの負担が重いというデータがあるからです。実際にKDDIでは、パスキーの導入によってサポートコールが3割減少したという実績があります。サポートのための人件費を節約することは長期的に見て大きなリターンになります。このような定量的な事例を用いて、費用を回収できるとことを説明します。([https://k-tai.watch.impress.co.jp/docs/news/1553203.html](https://k-tai.watch.impress.co.jp/docs/news/1553203.html))

次に、**ユーザー体験（UX）の向上が利用率と収益の増加に直結する**ことも強調します。パスキーは入力操作が少なく、ログイン時の離脱率を低下させることができます。これによって、継続利用者や課金利用者が増え、機会損失の削減を図ることができます。

さらに、**不正アクセスなどのセキュリティリスクを低減できるという点も重要です**。理由は、パスキーはフィッシング耐性があり、従来のパスワードに比べて攻撃者に悪用されるリスクが圧倒的に減らせます。個人情報漏洩はサイバーインシデント原因の上位にあり、これに伴う補償費用や訴訟リスクは無視できません。事故発生時の損害や訴訟リスクを下げることは、経営をする上で必須です。([https://www.ipa.go.jp/pressrelease/2024/press20250214.html](https://www.ipa.go.jp/pressrelease/2024/press20250214.html))

最後に導入の現実性を説明します。いくらメリットを説明しても現実的に実現が厳しければ提案することができません。しかし主要なプラットフォーム（Google、Apple、Microsoft）はすでにパスキーを標準でサポートしており、既存の認証基盤との共存も可能です。一斉にパスキーに移行することはリスクもあるので段階的に導入できることも訴求ポイントだと考えます。

以上のように、経営に直結する収益増加とインシデントの予防を強調して経営陣に合理性のある導入提案を行いたいと考えます。
